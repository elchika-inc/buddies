#!/usr/bin/env node
/**
 * ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 */
import sqlite3 from 'sqlite3';
import { open } from 'sqlite';
import path from 'path';
import fs from 'fs/promises';
import { PetHomeCrawler } from '../src/crawlers/PetHomeCrawler';
import { Env, Pet } from '../src/types';
import dotenv from 'dotenv';

// ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
dotenv.config({ path: '.dev.vars' });

// ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
const args = process.argv.slice(2);
const petType = args[0] as 'dog' | 'cat';
const limit = parseInt(args[1] || '30', 10);

if (!petType || !['dog', 'cat'].includes(petType)) {
  console.error('Usage: npm run crawl <dog|cat> [limit]');
  console.error('Example: npm run crawl dog 30');
  process.exit(1);
}

// ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒç”¨ã®ãƒ¢ãƒƒã‚¯Env
class LocalEnv implements Env {
  PET_HOME_BASE_URL = process.env.PET_HOME_BASE_URL || 'https://www.pet-home.jp';
  DATABASE_PATH = process.env.DATABASE_PATH || '../data/pawmatch.db';
  IMAGES_PATH = process.env.IMAGES_PATH || '../data/images';
  
  DB: any;
  IMAGES_BUCKET: any;
  
  constructor() {
    this.initDatabase();
    this.initImageStorage();
  }
  
  async initDatabase() {
    const dbPath = path.resolve(__dirname, '../../', this.DATABASE_PATH);
    console.log(`Database path: ${dbPath}`);
    
    const db = await open({
      filename: dbPath,
      driver: sqlite3.Database,
    });
    
    // D1 APIäº’æ›ã®ãƒ©ãƒƒãƒ‘ãƒ¼
    this.DB = {
      prepare: (query: string) => {
        return {
          bind: (...params: any[]) => {
            return {
              first: async () => {
                return await db.get(query, ...params);
              },
              all: async () => {
                const result = await db.all(query, ...params);
                return { results: result };
              },
              run: async () => {
                return await db.run(query, ...params);
              }
            };
          }
        };
      }
    };
  }
  
  initImageStorage() {
    const imagesPath = path.resolve(__dirname, '../../', this.IMAGES_PATH);
    
    // R2 APIäº’æ›ã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ï¼‰
    this.IMAGES_BUCKET = {
      put: async (key: string, data: ArrayBuffer | Blob, options?: any) => {
        const filePath = path.join(imagesPath, key);
        const dir = path.dirname(filePath);
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        await fs.mkdir(dir, { recursive: true });
        
        // Blobã‚’ãƒãƒƒãƒ•ã‚¡ãƒ¼ã«å¤‰æ›
        let buffer: Buffer;
        if (data instanceof Blob) {
          const arrayBuffer = await data.arrayBuffer();
          buffer = Buffer.from(arrayBuffer);
        } else {
          buffer = Buffer.from(data);
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        await fs.writeFile(filePath, buffer);
        
        // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if (options?.customMetadata) {
          const metaPath = `${filePath}.meta.json`;
          await fs.writeFile(metaPath, JSON.stringify({
            ...options.customMetadata,
            httpMetadata: options.httpMetadata,
          }, null, 2));
        }
        
        console.log(`Saved image: ${filePath}`);
      },
      
      get: async (key: string) => {
        const filePath = path.join(imagesPath, key);
        try {
          const data = await fs.readFile(filePath);
          return {
            body: data,
            customMetadata: {},
          };
        } catch (error) {
          return null;
        }
      }
    };
  }
}

// ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®å®Ÿè¡Œ
async function runCrawler() {
  console.log(`\nğŸ¾ PawMatch Crawler - Fetching ${limit} ${petType}s from Pet-Home\n`);
  
  try {
    // ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    const env = new LocalEnv();
    await env.initDatabase();
    
    // ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–
    const crawler = new PetHomeCrawler(env);
    
    // ã‚¯ãƒ­ãƒ¼ãƒ«å®Ÿè¡Œ
    const result = await crawler.crawl(petType, {
      limit,
      useDifferential: false, // åˆå›ã¯å…¨ä»¶å–å¾—
      forceFullScan: true,
    });
    
    // çµæœã‚’è¡¨ç¤º
    console.log('\nğŸ“Š Crawl Results:');
    console.log(`âœ… Total pets fetched: ${result.totalPets}`);
    console.log(`ğŸ†• New pets added: ${result.newPets}`);
    console.log(`ğŸ”„ Updated pets: ${result.updatedPets}`);
    
    if (result.errors.length > 0) {
      console.log(`âŒ Errors: ${result.errors.length}`);
      result.errors.forEach(error => console.error(`  - ${error}`));
    }
    
    console.log('\nâœ¨ Crawling completed successfully!');
    
  } catch (error) {
    console.error('âŒ Crawler failed:', error);
    process.exit(1);
  }
}

// å®Ÿè¡Œ
runCrawler();